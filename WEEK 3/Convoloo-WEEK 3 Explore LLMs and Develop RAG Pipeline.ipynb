{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44666a45-f6cf-4148-a34b-a95cf3124aa2",
   "metadata": {},
   "source": [
    "# WEEK 3: Explore LLMs and Develop RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d5cae-a4ce-48e8-9468-079d0417e738",
   "metadata": {},
   "source": [
    "### Week 3: Explore LLMs and Develop a Retrieval-Augmented Generation (RAG) Pipeline\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "1. **Reasearch and PDF report on Large Language Models (LLMs) and LangChain:**\n",
    "   - Learn about different LLMs available, both open-source (like GPT-3, GPT-4) and closed-source options.\n",
    "   - Understand the capabilities, advantages, and limitations of each model.\n",
    "   - Learn about LangChain.\n",
    "\n",
    "2. **Select an LLM:**\n",
    "   - Choose an LLM that fits MY project requirements based on factors like performance, ease of integration, and cost.\n",
    "\n",
    "3. **Set Up the LLM:**\n",
    "   - Integrate the chosen LLM into MY project. This involves setting up API keys, handling requests, and managing responses.\n",
    "\n",
    "4. **Develop the Retrieval-Augmented Generation (RAG) Pipeline:**\n",
    "   - Implement a system that uses the LLM to generate responses based on user queries and the preprocessed restaurant data.\n",
    "   - The RAG pipeline typically involves two main steps: retrieving relevant data and generating a response.\n",
    "\n",
    "5. **Test the Pipeline:**\n",
    "   - Test the RAG pipeline with different queries to ensure it returns accurate and relevant results.\n",
    "   - Debug and refine the pipeline as needed.\n",
    "\n",
    "#### Choice 1: without LangChain, but use the selected LLM directly.\n",
    "\n",
    "##### 1. Understand Large Language Models (LLMs)\n",
    "\n",
    "See PDF.\n",
    "\n",
    "##### 2. Select an LLM\n",
    "\n",
    "For this example, we will use OpenAI's GPT-3.\n",
    "\n",
    "##### 3. Set Up the LLM\n",
    "\n",
    "First, ME need to sign up for access to OpenAI's API and get an API key.\n",
    "\n",
    "**Install the OpenAI package:**\n",
    "\n",
    "```bash\n",
    "npm install openai\n",
    "```\n",
    "\n",
    "**Set Up the API Key:**\n",
    "\n",
    "Create a file named `.env` in the root of MY React project and add MY OpenAI API key:\n",
    "\n",
    "```\n",
    "REACT_APP_OPENAI_API_KEY=MY_openai_api_key\n",
    "```\n",
    "\n",
    "**Load the API Key in MY project:**\n",
    "\n",
    "**App.js**\n",
    "\n",
    "```jsx\n",
    "import React, { useState } from 'react';\n",
    "import axios from 'axios';\n",
    "import './App.css';\n",
    "\n",
    "function App() {\n",
    "  const [query, setQuery] = useState('');\n",
    "  const [results, setResults] = useState([]);\n",
    "\n",
    "  const handleSearch = async () => {\n",
    "    try {\n",
    "      const response = await axios.post('http://localhost:5000/search', { query });\n",
    "      setResults(response.data);\n",
    "    } catch (error) {\n",
    "      console.error('Error fetching data', error);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"App\">\n",
    "      <header className=\"App-header\">\n",
    "        <h1>Restaurant Cuisine Finder</h1>\n",
    "        <input\n",
    "          type=\"text\"\n",
    "          placeholder=\"Enter MY query...\"\n",
    "          value={query}\n",
    "          onChange={(e) => setQuery(e.target.value)}\n",
    "        />\n",
    "        <button onClick={handleSearch}>Search</button>\n",
    "        <div className=\"results\">\n",
    "          {results.map((result, index) => (\n",
    "            <div key={index} className=\"result\">\n",
    "              <h2>{result.name}</h2>\n",
    "              <p>{result.address}</p>\n",
    "              <p>Rating: {result.rating}</p>\n",
    "              <p>Price Level: {result.price_level}</p>\n",
    "            </div>\n",
    "          ))}\n",
    "        </div>\n",
    "      </header>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n",
    "```\n",
    "\n",
    "##### 4. Develop the Retrieval-Augmented Generation (RAG) Pipeline\n",
    "\n",
    "**Flask Backend (Python)**\n",
    "\n",
    "First, ensure ME have Flask and Flask-CORS installed:\n",
    "\n",
    "```bash\n",
    "pip install flask flask-cors openai pandas\n",
    "```\n",
    "\n",
    "**app.py**\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "openai.api_key = 'MY_OPENAI_API_KEY'\n",
    "\n",
    "# Load the restaurant data\n",
    "df = pd.read_csv('cleaned_restaurants.csv')\n",
    "\n",
    "def generate_response(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def rag_pipeline(query, dataframe):\n",
    "    relevant_data = dataframe[dataframe['name'].str.contains(query, case=False, na=False)]\n",
    "    context = relevant_data.to_string(index=False)\n",
    "    prompt = f\"Answer the following question based on the context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    return generate_response(prompt)\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    query = request.json.get('query')\n",
    "    response = rag_pipeline(query, df)\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "##### 5. Test the Pipeline\n",
    "\n",
    "With MY backend running, ME can now test the full pipeline:\n",
    "\n",
    "- Start MY Flask server: `python app.py`\n",
    "- In MY React app, enter a query and click \"Search\" to see the generated responses.\n",
    "\n",
    "### Summary\n",
    "\n",
    "1. **Understand Large Language Models (LLMs):**\n",
    "   - Research and evaluate different LLMs.\n",
    "   - Understand their capabilities and limitations.\n",
    "\n",
    "2. **Select an LLM:**\n",
    "   - Choose the most suitable LLM for MY project.\n",
    "\n",
    "3. **Set Up the LLM:**\n",
    "   - Obtain API keys and set up the environment.\n",
    "   - Integrate the LLM into MY project.\n",
    "\n",
    "4. **Develop the RAG Pipeline:**\n",
    "   - Implement a system to retrieve relevant data and generate responses using the LLM.\n",
    "\n",
    "5. **Test the Pipeline:**\n",
    "   - Test with various queries to ensure the system works as expected.\n",
    "\n",
    "By following these steps, ME'll have a functioning RAG pipeline that leverages a large language model to provide relevant and accurate responses based on user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d9a30-cc2a-47ff-ac69-2d15664ed2af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a5f8369-0d68-4952-9ca4-29d819e5c956",
   "metadata": {},
   "source": [
    "### Step-by-Step Signing Up for Access to OpenAI's API and Get an API Key\n",
    "\n",
    "#### 1. Register for an OpenAI Account\n",
    "1. **Visit OpenAI's Website:**\n",
    "   - Go to [OpenAI's official website](https://www.openai.com/).\n",
    "\n",
    "2. **Sign Up:**\n",
    "   - Click on the \"Sign Up\" button located at the top right corner of the page.\n",
    "   - Provide MY email address and create a password to register for an account. ME can also sign up using MY Google or Microsoft account.\n",
    "\n",
    "#### 2. Verify MY Email Address\n",
    "1. **Check MY Email:**\n",
    "   - Open the verification email sent by OpenAI to the email address ME used to sign up.\n",
    "   \n",
    "2. **Verify:**\n",
    "   - Click on the verification link in the email to verify MY account.\n",
    "\n",
    "#### 3. Apply for API Access\n",
    "1. **Go to the API Section:**\n",
    "   - Once logged in, navigate to the \"API\" section on the OpenAI website.\n",
    "\n",
    "2. **Apply for Access:**\n",
    "   - Follow the instructions to apply for API access. This may include providing some information about how ME plan to use the API.\n",
    "\n",
    "#### 4. Obtain MY API Key\n",
    "1. **API Key:**\n",
    "   - After MY application is approved, ME will receive access to the API key.\n",
    "   \n",
    "2. **Access the Key:**\n",
    "   - Go to MY OpenAI account dashboard.\n",
    "   - Navigate to the API section and find MY API key.\n",
    "\n",
    "3. **Copy the API Key:**\n",
    "   - Copy the provided API key. ME will need this key to authenticate MY API requests.\n",
    "\n",
    "#### 5. Set Up the API Key in MY Project\n",
    "1. **Create a `.env` File:**\n",
    "   - In the root directory of MY React project, create a file named `.env`.\n",
    "\n",
    "2. **Add the API Key to the `.env` File:**\n",
    "   - Open the `.env` file and add the following line, replacing `my_openai_api_key` with my actual API key:\n",
    "\n",
    "3. **Load the API Key in MY React Project:**\n",
    "   - Use the `dotenv` package or another method to load environment variables in MY React project.\n",
    "\n",
    "**Example in React:**\n",
    "\n",
    "**App.js**\n",
    "\n",
    "```jsx\n",
    "import React, { useState } from 'react';\n",
    "import axios from 'axios';\n",
    "import './App.css';\n",
    "\n",
    "function App() {\n",
    "  const [query, setQuery] = useState('');\n",
    "  const [results, setResults] = useState([]);\n",
    "\n",
    "  const handleSearch = async () => {\n",
    "    try {\n",
    "      const response = await axios.post('http://localhost:5000/search', { query });\n",
    "      setResults(response.data);\n",
    "    } catch (error) {\n",
    "      console.error('Error fetching data', error);\n",
    "    }\n",
    "  };\n",
    "\n",
    "  return (\n",
    "    <div className=\"App\">\n",
    "      <header className=\"App-header\">\n",
    "        <h1>Restaurant Cuisine Finder</h1>\n",
    "        <input\n",
    "          type=\"text\"\n",
    "          placeholder=\"Enter MY query...\"\n",
    "          value={query}\n",
    "          onChange={(e) => setQuery(e.target.value)}\n",
    "        />\n",
    "        <button onClick={handleSearch}>Search</button>\n",
    "        <div className=\"results\">\n",
    "          {results.map((result, index) => (\n",
    "            <div key={index} className=\"result\">\n",
    "              <h2>{result.name}</h2>\n",
    "              <p>{result.address}</p>\n",
    "              <p>Rating: {result.rating}</p>\n",
    "              <p>Price Level: {result.price_level}</p>\n",
    "            </div>\n",
    "          ))}\n",
    "        </div>\n",
    "      </header>\n",
    "    </div>\n",
    "  );\n",
    "}\n",
    "\n",
    "export default App;\n",
    "```\n",
    "\n",
    "**.env**\n",
    "\n",
    "```plaintext\n",
    "<!-- REACT_APP_OPENAI_API_KEY=MY_openai_api_key -->\n",
    "REACT_APP_OPENAI_API_KEY=my_openai_api_key\n",
    "```\n",
    "\n",
    "#### 6. Use the API Key in MY Backend\n",
    "\n",
    "**Flask Backend (Python)**\n",
    "\n",
    "```python\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import openai\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "openai.api_key = 'MY_OPENAI_API_KEY'\n",
    "\n",
    "# Load the restaurant data\n",
    "df = pd.read_csv('cleaned_restaurants.csv')\n",
    "\n",
    "def generate_response(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "def rag_pipeline(query, dataframe):\n",
    "    relevant_data = dataframe[dataframe['name'].str.contains(query, case=False, na=False)]\n",
    "    context = relevant_data.to_string(index=False)\n",
    "    prompt = f\"Answer the following question based on the context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    return generate_response(prompt)\n",
    "\n",
    "@app.route('/search', methods=['POST'])\n",
    "def search():\n",
    "    query = request.json.get('query')\n",
    "    response = rag_pipeline(query, df)\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "```\n",
    "\n",
    "By following these detailed steps, ME can sign up for access to OpenAI's API, obtain an API key, and integrate it into MY project to develop the Retrieval-Augmented Generation (RAG) pipeline for MY application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9373e-cc31-4b71-8fb2-430a4caae977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65ea8511-6be4-460f-aef5-e45a2acee1f9",
   "metadata": {},
   "source": [
    "## Choice 2: Use LangChain to develope RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515eaee-0722-4bbd-8ee0-eb7bc2d4f45d",
   "metadata": {},
   "source": [
    "Below are the steps and example code for implementing this week's tasks using LangChain. LangChain is a framework for building applications powered by large language models (LLMs), making it particularly suitable for tasks like Retrieval-Augmented Generation (RAG).\n",
    "\n",
    "### Install LangChain\n",
    "\n",
    "First, install LangChain and the necessary libraries:\n",
    "\n",
    "```bash\n",
    "pip install langchain openai faiss-cpu\n",
    "```\n",
    "\n",
    "### Step 1: Initialize OpenAI API\n",
    "\n",
    "Use the OpenAI API key got in the above steps to access the GPT models. \n",
    "\n",
    "```python\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Set the API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"MY-openai-api-key\"\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = OpenAI(temperature=0.7)\n",
    "```\n",
    "\n",
    "### Step 2: Build the Retrieval-Augmented Generation (RAG) Pipeline \n",
    "\n",
    "Use LangChain's `RetrievalQA` component to easily implement the RAG pipeline.\n",
    "\n",
    "#### Example Code:\n",
    "\n",
    "```python\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "# Load documents\n",
    "documents = [\n",
    "    {\"text\": \"The restaurant is known for its Italian cuisine and excellent service.\"},\n",
    "    {\"text\": \"This place offers a variety of Asian dishes at affordable prices.\"},\n",
    "    {\"text\": \"Famous for its desserts and cozy atmosphere.\"},\n",
    "]\n",
    "\n",
    "# Initialize the document loader\n",
    "loader = TextLoader(documents=documents)\n",
    "\n",
    "# Use FAISS as the vector store\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(loader.load(), embedding)\n",
    "\n",
    "# Create the RAG pipeline\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")\n",
    "\n",
    "# Process a user query\n",
    "query = \"Tell me about Italian restaurants.\"\n",
    "response = rag_chain.run(query)\n",
    "print(\"Generated Response:\", response)\n",
    "```\n",
    "\n",
    "### Step 3: Integrate into the Application (do it when integrating backend afterwards.)\n",
    "\n",
    "1. **Backend Integration**\n",
    "   - Integrate the above code into MY application's backend to handle user inputs and generate responses.\n",
    "\n",
    "2. **Testing and Evaluation**\n",
    "   - Run multiple test cases to ensure the RAG pipeline returns accurate and user-expected responses.\n",
    "\n",
    "### Step 4: Initial Testing and Evaluation (do it after the project can run successfully afterwards.)\n",
    "\n",
    "1. **Performance Evaluation**\n",
    "   - Test the response time and accuracy, and adjust parameters to optimize performance.\n",
    "\n",
    "2. **User Feedback**\n",
    "   - Collect and analyze user feedback to ensure the system meets real-world usage needs.\n",
    "\n",
    "### Step 5: Documentation (do it when writing report for this project afterwards.)\n",
    "\n",
    "1. **Document the Development Process**\n",
    "   - Record the steps involved in building the RAG pipeline using LangChain, including any challenges and solutions encountered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
